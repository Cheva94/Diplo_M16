{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplomatura en ciencia de datos, aprendizaje automático y sus aplicaciones - Edición 2023 - FAMAF (UNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mentoría 16 - ¿Cómo identificar fuga de ventas? Inteligencia artificial aplicada al sector comercial.\n",
    "\n",
    "### Explorando Patrones de Datos a través de Clustering (TP3) - Parte 1: Preparación de los datos\n",
    "\n",
    "**Integrantes:**\n",
    "- Canalis, Patricio.\n",
    "- Chevallier-Boutell, Ignacio José.\n",
    "- Villarroel Torrez, Daniel.\n",
    "\n",
    "**Mentores:**\n",
    "- Gonzalez, Lucía\n",
    "- Lahoz, Nahuel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para que las funciones se actualicen sin tener que refrescar el kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Funciones de visualización y curación\n",
    "import pandas as pd\n",
    "import json\n",
    "from os.path import exists\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from scipy.stats import linregress as LR\n",
    "from scipy.stats import skew, kurtosis, skewtest, kurtosistest\n",
    "\n",
    "# Funciones de clustering\n",
    "from sklearn.cluster import KMeans, MeanShift\n",
    "from sklearn import manifold, preprocessing, decomposition\n",
    "\n",
    "# Funciones propias\n",
    "from utils_limpieza import * \n",
    "\n",
    "# Clear preferencias\n",
    "plt.rcdefaults()\n",
    "pd.reset_option('^display\\.float_format')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Preparación de Datos <span style=\"color:magenta\">**(Paso 1)**</span>\n",
    "\n",
    "Se repiten los pasos de curación realizados en la entrega anterior. A tener en cuenta:\n",
    "* Algunos pasos que se hacían por separado, ahora se hacen todos juntos. \n",
    "* No se simplifica la variable `Deposito`, ya que se descarta desde el principio.\n",
    "* lo del 10K\n",
    "* No se hace el cálculo de promedio y varianza de los vectores finales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cargamos el dataset crudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/raw/tp2_muestra_diplodatos_ventas_omega_modelo_2023.csv'\n",
    "ventas_raw = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Eliminamos las siguientes variables:\n",
    "    * `INSCRIPCION`.\n",
    "    * `CATEGORIA`.\n",
    "    * `DESCRIPCION_CATEGORIA`.\n",
    "    * `CATEGORIA (Ajustado)`.\n",
    "    * `NOMBRE`.\n",
    "    * `'CM04`.\n",
    "    * `DESC_TRATAMIENTO_FISCAL`.\n",
    "    * `TRATAMIENTO_DIFERNCIAL`.\n",
    "    * `TRATAMIENTO_FISCAL`.\n",
    "    * `PORCENTAJE_COMISION_EMPRESA`.\n",
    "    * `DEPOSITO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas = limpiar_basic(ventas_raw, cols_drop=['INSCRIPCION', 'CATEGORIA', \n",
    "                                                  'DESCRIPCION_CATEGORIA', \n",
    "                                                  'CATEGORIA (Ajustado)', \n",
    "                                                  'NOMBRE', 'CM04', 'DEPOSITO',\n",
    "                                                  'DESC_TRATAMIENTO_FISCAL', \n",
    "                                                  'TRATAMIENTO_DIFERNCIAL', \n",
    "                                                  'TRATAMIENTO_FISCAL', \n",
    "                                                  'PORCENTAJE_COMISION_EMPRESA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Renombramos como `Otros` las subcategorías que no tengan al menos 1 `MODELO` = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas = renombrar_elementos(ventas, columna='SUB-CATEGORIA', \n",
    "                                     fill_otros='Otros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Eliminamos los registros que contienen las siguientes subcategorías:\n",
    "    * `Otros`.\n",
    "    * `Instalación, Mantenimiento, Reparación, etc de productos varios` (a.k.a. `Mantenimiento`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas = ventas[ventas['SUB-CATEGORIA'] != 'Otros'].copy()\n",
    "ventas = ventas[ventas['SUB-CATEGORIA'] != 'Instalación, Mantenimiento, Reparación, etc de productos varios'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Creamos la variable `Fecha`, que surge como:\n",
    "    $$Fecha = Año + Mes$$\n",
    "\n",
    "    Luego, eliminamos las variables `MES` y `AÑO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas[\"Fecha\"] = pd.to_datetime(ventas['MES'].astype(str) + '-' + ventas['AÑO'].astype(str), format='%m-%Y')\n",
    "ventas = limpiar_basic(ventas, cols_drop=['MES', 'AÑO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Anonimizamos la variable sensible `ID_VENDEDOR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas, _ = anonimizar(ventas, 'ID_VENDEDOR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Simplificamos el nombre de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../references/tp2_column_dict.json\") as column_dict_json:\n",
    "    column_dict = json.load(column_dict_json)\n",
    "\n",
    "ventas.rename(columns = column_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Simplificamos las categorías en `Subrubro`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../references/tp2_subrubro_dict.json\") as subrubro_dict_json:\n",
    "    subrubro_dict = json.load(subrubro_dict_json)\n",
    "\n",
    "ventas['Subrubro'] = ventas['Subrubro'].replace(subrubro_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. <span style=\"color:magenta\">**(Este paso es nuevo)**</span> Remplazamos con $0 a todas las ventas y comisiones que estén en el rango desde -$10.000 hasta $10.000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas[['Ventas', 'Comision']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 10000\n",
    "a = ventas[(ventas['Ventas'] < cut) & (ventas['Ventas'] > - cut)].copy()\n",
    "b = a[a['Ventas']==0].copy()\n",
    "print(f'Se trata de {a.shape[0]} registros. De los cuales {b.shape[0]} ya son idénticamente nulos.')\n",
    "print(f'Es decir que tenemos {a.shape[0] - b.shape[0]} registros que no son nulos dentro de este rango (${-cut}, ${cut}).')\n",
    "c = a[a['Ventas'] != 0].copy()\n",
    "cpos = c[c['Ventas']>0]\n",
    "cneg = c[c['Ventas']<0]\n",
    "print(f'De los valores no nulos, hay {cpos.shape[0]} positivos y {cneg.shape[0]} negativos.')\n",
    "\n",
    "sns.histplot(cpos['Ventas'])\n",
    "sns.histplot(cneg['Ventas'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputamos las ventas\n",
    "ven = ventas['Ventas'].copy()\n",
    "ven.mask((ven < cut) & (ven > - cut), inplace=True)\n",
    "ven.fillna(0, inplace=True)\n",
    "ventas['Ventas'] = ven\n",
    "\n",
    "# Imputamos las comisiones\n",
    "ven = ventas['Comision'].copy()\n",
    "ven.mask((ven < cut) & (ven > - cut), inplace=True)\n",
    "ven.fillna(0, inplace=True)\n",
    "ventas['Comision'] = ven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Eliminamos el efecto de la inflación. El procedimiento es el siguiente:\n",
    "    $$\\text{VAR}_{mm-aaaa} \\frac{\\text{IPC}_{06-2022}}{\\text{IPC}_{mm-aaaa}}$$\n",
    "\n",
    "    Para todo valor de cada variable (VAR) correspondiente a cierto mes \"mm-aaaa\" se lo divide por el Índice de Precios al Consumidor (IPC) correspondiente a ese mes \"mm-aaaa\" y luego se lo multiplica por el IPC correspondiente al mes \"06-2022\". De esta forma, todos los valores de cada variable VAR van a quedar expresados en unidades monetarias del \"06-2022\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios_path = \"../data/external/tp2_IPC_Indec.csv\"\n",
    "\n",
    "if exists(precios_path):\n",
    "    print('Este archivo ya existe.')\n",
    "else:\n",
    "    print('Este archivo no existe: ¡Vamos a crearlo!')\n",
    "    url = \"https://www.indec.gob.ar/ftp/cuadros/economia/sh_ipc_06_23.xls\"\n",
    "    df = pd.read_excel(url, sheet_name=\"Índices IPC Cobertura Nacional\", header=None, usecols=\"B:CA\", skiprows=[0, 1, 2, 3, 4, 6, 7, 8], nrows=2)\n",
    "    df = df.transpose()\n",
    "    df.columns = [\"Fecha\", \"INDICE\"]\n",
    "    df[\"Fecha\"] = pd.to_datetime(df[\"Fecha\"])\n",
    "    df.to_csv(precios_path, index=False)\n",
    "\n",
    "precios = pd.read_csv(precios_path)\n",
    "\n",
    "# Hay que asegurar que la variable clave tenga el mismo tipo en los dos dataframes\n",
    "precios[\"Fecha\"] = pd.to_datetime(precios[\"Fecha\"])\n",
    "\n",
    "ventas = ventas.merge(precios[[\"Fecha\", \"INDICE\"]], on=\"Fecha\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos la imputación\n",
    "indexar(ventas, 'Ventas')\n",
    "indexar(ventas, 'Comision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se descartan las variables que no se usan\n",
    "ventas = limpiar_basic(ventas, cols_drop=['Ventas', 'Comision', 'INDICE'])\n",
    "\n",
    "# Se renombran las variables\n",
    "ventas.rename(columns = {'Ventas_Real': 'Ventas', \n",
    "                              'Comision_Real': 'Comision'}, inplace = True)\n",
    "\n",
    "# Se reacomodan las columnas\n",
    "ventas = ventas[['ID', 'Omega', 'Subrubro', 'Fecha', 'Ventas', 'Comision', 'Modelo']]\n",
    "\n",
    "ventas = ventas.sort_values(['Fecha', 'Ventas']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Para cada combinación posible de `Subrubro`, `ID` y `Fecha`, vamos a:\n",
    "    * Sumar todos los valores de `Ventas`.\n",
    "    * Sumar todos los valores de `Comision`.\n",
    "    * Mantener los valores de `Modelo` y de `Omega`.\n",
    "\n",
    "    Al hacer esto, se agregan en una única fila todas las observaciones que pertenezcan a un mismo vendedor en una dada fecha bajo un cierto subrubro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregado = ventas.groupby(['Subrubro', 'ID', 'Fecha']).agg({\n",
    "    'Omega': 'min',\n",
    "    'Ventas': 'sum',\n",
    "    'Comision': 'sum',\n",
    "    'Modelo': 'min'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Se eliminan los registros asociados a vendedores que tienen siempre ventas nulas dentro de un mismo subrubro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregado_no_nulo = agregado.groupby(['Subrubro', 'ID']).filter(lambda x: (x['Ventas'] != 0).any()).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Deberíamos tener 42 observaciones por par ID/Subrubro. Imputamos los meses faltantes con valor 0 en ventas y en comisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distinguimos los valores originales de los imputados (`Dato_original`).\n",
    "agregado_no_nulo['Dato_original'] = 1\n",
    "\n",
    "# Contar las observaciones por combinación de ID y Subrubro\n",
    "conteo_combinaciones = agregado_no_nulo.groupby(['Subrubro', 'ID']).size().reset_index(name='Conteo')\n",
    "\n",
    "# Filtrar las combinaciones con menos de 42 observaciones\n",
    "combinaciones_faltantes = conteo_combinaciones[conteo_combinaciones['Conteo'] < 42]\n",
    "\n",
    "# Lista para almacenar las observaciones faltantes\n",
    "observaciones_faltantes = []\n",
    "\n",
    "# Iterar sobre las combinaciones faltantes\n",
    "for _, combinacion in combinaciones_faltantes.iterrows():\n",
    "    id_val = combinacion['ID']\n",
    "    subrubro_val = combinacion['Subrubro']\n",
    "    \n",
    "    # Obtener fechas existentes y fechas faltantes\n",
    "    fechas_existentes = agregado_no_nulo[(agregado_no_nulo['ID'] == id_val) & (agregado_no_nulo['Subrubro'] == subrubro_val)]['Fecha']\n",
    "    fechas_faltantes = set(agregado_no_nulo['Fecha'].unique()) - set(fechas_existentes)\n",
    "    \n",
    "    # Agregar observaciones faltantes al DataFrame\n",
    "    for fecha_faltante in fechas_faltantes:\n",
    "        observacion = {\n",
    "            'ID': id_val,\n",
    "            'Subrubro': subrubro_val,\n",
    "            'Fecha': fecha_faltante,\n",
    "            'Ventas': 0,\n",
    "            'Comision': 0,\n",
    "        }\n",
    "        observaciones_faltantes.append(observacion)\n",
    "\n",
    "# Crear DataFrame con las observaciones faltantes\n",
    "df_observaciones_faltantes = pd.DataFrame(observaciones_faltantes)\n",
    "\n",
    "# Agregar observaciones faltantes al DataFrame agregado_no_nulo\n",
    "agregado_limpio = pd.concat([agregado_no_nulo, df_observaciones_faltantes], ignore_index=True)\n",
    "\n",
    "# Imputo los valores Omega y Modelo asociados a los nuevos meses adicionados. Es más eficiente agregarlo en una celda aparte y no en el for (antes demoraba 9 minutos, ahora menos de 1).\n",
    "agregado_limpio['Omega'] = agregado_limpio.groupby(['ID', 'Subrubro'])['Omega'].transform('max')\n",
    "agregado_limpio['Modelo'] = agregado_limpio.groupby(['ID', 'Subrubro'])['Modelo'].transform('max')\n",
    "\n",
    "# Relleno los valores nulos de Dato_original con 0.\n",
    "agregado_limpio['Dato_original'] = agregado_limpio['Dato_original'].fillna(0)\n",
    "\n",
    "# Convertir las columnas 'Omega', 'Modelo' y 'Dato_original' a tipo int64\n",
    "agregado_limpio['Omega'] = agregado_limpio['Omega'].astype('int64')\n",
    "agregado_limpio['Modelo'] = agregado_limpio['Modelo'].astype('int64')\n",
    "agregado_limpio['Dato_original'] = agregado_limpio['Dato_original'].astype('int64')\n",
    "\n",
    "promedio_observaciones = agregado_limpio.groupby(['Subrubro', 'ID']).size().mean()\n",
    "\n",
    "# Mostrar el promedio de observaciones por combinación de ID y Subrubro\n",
    "print(f'Cade vendedor tiene asociados {promedio_observaciones} meses diferentes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Ordenar luego de todo lo que se hizo. Dejar que primero esté Fecha. Sirve para el pivoteo que hacemos después."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registros_vendedores_abs = agregado_limpio.sort_values(['Fecha', 'Subrubro', 'ID']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Queremos hacer el cálculo de la varación porcentual. Con el dataset como está actualmente (presencia de ceros), pueden generarse resultados que tienden a infinito. Para superar esta situación, se reemplazan todos los ceros por NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registros_vendedores_rel = registros_vendedores_abs.copy()\n",
    "registros_vendedores_rel[['Ventas', 'Comision']] = registros_vendedores_rel[['Ventas', 'Comision']].replace({0:np.NaN})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Cálculo de cambios porcentuales. \n",
    "\n",
    "    **NOTA:** La función pct_change devuelve en el rango normal, no en el porcentual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_diferencia_porcentual(registros_vendedores_rel, 'Ventas', 12)\n",
    "crear_diferencia_porcentual(registros_vendedores_rel, 'Comision', 12)\n",
    "crear_diferencia_porcentual(registros_vendedores_rel, 'Ventas', 4)\n",
    "crear_diferencia_porcentual(registros_vendedores_rel, 'Comision', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Pivotear los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivotear = registros_vendedores_rel.copy()\n",
    "\n",
    "# Extraer el mes y el año de la columna \"Fecha\"\n",
    "pivotear[\"Fecha\"] = pd.to_datetime(pivotear[\"Fecha\"])\n",
    "pivotear[\"Month\"] = pivotear[\"Fecha\"].dt.month\n",
    "pivotear[\"Year\"] = pivotear[\"Fecha\"].dt.year\n",
    "\n",
    "# Convertir \"Month\" a string con formato de dos cifras\n",
    "pivotear[\"Month\"] = pivotear[\"Month\"].apply(lambda x: str(x).zfill(2))\n",
    "\n",
    "# Convertir \"Year\" a string y quedarse con los últimos 2 dígitos\n",
    "pivotear[\"Year\"] = pivotear[\"Year\"].apply(lambda x: str(x)[-2:])\n",
    "\n",
    "# Crear la variable \"Fecha2\" que concatena \"Year\" y \"Month\"\n",
    "pivotear[\"Fecha2\"] = pivotear[\"Year\"] + pivotear[\"Month\"]\n",
    "\n",
    "# Eliminar columnas\n",
    "pivotear.drop(columns=['Fecha','Ventas','Comision','Dato_original','Month','Year'], inplace=True)\n",
    "\n",
    "# Renombrar la columnas\n",
    "pivotear.rename(columns={'Fecha2': 'Fecha', 'Y_pct_Ventas': 'Y_pct_Ven', 'Y_pct_Comision': 'Y_pct_Com', 'F_pct_Ventas': 'F_pct_Ven', 'F_pct_Comision': 'F_pct_Com'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar el pivoteo y la agrupación\n",
    "pivot_df = pivotear.pivot_table(index=[\"ID\",'Subrubro','Omega','Modelo'], columns=['Fecha'], values=['Y_pct_Ven', 'Y_pct_Com', 'F_pct_Ven', 'F_pct_Com'])\n",
    "\n",
    "# Generar los nombres de las columnas finales\n",
    "columns = [f\"{col[0]}_{col[1]}\" for col in pivot_df.columns]\n",
    "\n",
    "# Asignar los nuevos nombres de columnas\n",
    "pivot_df.columns = columns\n",
    "\n",
    "# Restablecer el índice para que \"ID\" vuelva a ser una columna\n",
    "pivot_df = pivot_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Guaradamos todo lo hecho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.to_csv('../data/interim/tp3_vendedores_vector.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
