{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplomatura en ciencia de datos, aprendizaje automático y sus aplicaciones - Edición 2023 - FAMAF (UNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mentoría 16 - ¿Cómo identificar fuga de ventas? Inteligencia artificial aplicada al sector comercial.\n",
    "\n",
    "### Explorando Patrones de Datos a través de Clustering (TP3) - Parte 1: Preparación de los datos\n",
    "\n",
    "**Integrantes:**\n",
    "- Canalis, Patricio.\n",
    "- Chevallier-Boutell, Ignacio José.\n",
    "- Villarroel Torrez, Daniel.\n",
    "\n",
    "**Mentores:**\n",
    "- Gonzalez, Lucía\n",
    "- Lahoz, Nahuel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para que las funciones se actualicen sin tener que refrescar el kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Funciones de visualización y curación\n",
    "import pandas as pd\n",
    "import json\n",
    "from os.path import exists\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from scipy.stats import linregress as LR\n",
    "from scipy.stats import skew, kurtosis, skewtest, kurtosistest\n",
    "\n",
    "# Funciones de clustering\n",
    "from sklearn.cluster import KMeans, MeanShift\n",
    "from sklearn import manifold, preprocessing, decomposition\n",
    "\n",
    "# Funciones propias\n",
    "from utils_limpieza import * \n",
    "\n",
    "# Clear preferencias\n",
    "plt.rcdefaults()\n",
    "pd.reset_option('^display\\.float_format')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Preparación de Datos <span style=\"color:magenta\">**(Paso 1)**</span>\n",
    "\n",
    "Se repiten los pasos de curación realizados en la entrega anterior, con algunas modificaciones que se creen necesarias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cargamos el dataset crudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/raw/tp2_muestra_diplodatos_ventas_omega_modelo_2023.csv'\n",
    "ventas = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Eliminamos las variables `INSCRIPCION`, `CATEGORIA`, `DESCRIPCION_CATEGORIA`, `CATEGORIA (Ajustado)`, `NOMBRE`, `'CM04`, `DESC_TRATAMIENTO_FISCAL`, `TRATAMIENTO_DIFERNCIAL`, `TRATAMIENTO_FISCAL` y `PORCENTAJE_COMISION_EMPRESA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_renamed = limpiar_basic(ventas, cols_drop=['INSCRIPCION', 'CATEGORIA', \n",
    "                                                  'DESCRIPCION_CATEGORIA', \n",
    "                                                  'CATEGORIA (Ajustado)', \n",
    "                                                  'NOMBRE', 'CM04', \n",
    "                                                  'DESC_TRATAMIENTO_FISCAL', \n",
    "                                                  'TRATAMIENTO_DIFERNCIAL', \n",
    "                                                  'TRATAMIENTO_FISCAL', \n",
    "                                                  'PORCENTAJE_COMISION_EMPRESA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Renombramos como `Otros` las subcategorías que no tengan al menos 1 `MODELO` = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_renamed = renombrar_elementos(ventas_renamed, \n",
    "                                     columna='SUB-CATEGORIA', \n",
    "                                     fill_otros='Otros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Eliminamos los registros que contienen `Otros` o `Instalación, Mantenimiento, Reparación, etc de productos varios` (a.k.a. `Mantenimiento`) como subcategoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_renamed = ventas_renamed[ventas_renamed['SUB-CATEGORIA'] != 'Otros'].copy()\n",
    "ventas_renamed = ventas_renamed[ventas_renamed['SUB-CATEGORIA'] != 'Instalación, Mantenimiento, Reparación, etc de productos varios'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Creamos la variable `Fecha`, que surge como:\n",
    "    $$Fecha = Año + Mes$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_renamed[\"Fecha\"] = pd.to_datetime(ventas_renamed['MES'].astype(str) + '-' + ventas_renamed['AÑO'].astype(str), format='%m-%Y')\n",
    "ventas_renamed = limpiar_basic(ventas_renamed, cols_drop=['MES', 'AÑO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Anonimizamos la variable sensible `ID_VENDEDOR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_hash, _ = anonimizar(ventas_renamed, 'ID_VENDEDOR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Simplificamos el nombre de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos\n",
    "with open(\"../references/tp2_column_dict.json\") as column_dict_json:\n",
    "    column_dict = json.load(column_dict_json)\n",
    "\n",
    "ventas_hash.rename(columns = column_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Simplificamos los valores en `Deposito`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_hash, _ = anonimizar(ventas_hash, 'Deposito')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Simplificamos las categorías en `Subrubro`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../references/tp2_subrubro_dict.json\") as subrubro_dict_json:\n",
    "    subrubro_dict = json.load(subrubro_dict_json)\n",
    "\n",
    "ventas_hash['Subrubro'] = ventas_hash['Subrubro'].replace(subrubro_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. acá va el paso nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Eliminamos el efecto de la inflación. El procedimiento es el siguiente:\n",
    "    $$\\text{VAR}_{mm-aaaa} \\frac{\\text{IPC}_{06-2022}}{\\text{IPC}_{mm-aaaa}}$$\n",
    "\n",
    "Para todo valor de cada variable (VAR) correspondiente a cierto mes \"mm-aaaa\" se lo divide por el Índice de Precios al Consumidor (IPC) correspondiente a ese mes \"mm-aaaa\" y luego se lo multiplica por el IPC correspondiente al mes \"06-2022\".\n",
    "\n",
    "De esta forma, todos los valores de cada variable VAR van a quedar expresados en unidades monetarias del \"06-2022\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_ipc = ventas_hash.copy()\n",
    "# ventas_ipc[\"Fecha\"] = pd.to_datetime(ventas_ipc[\"Fecha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios_path = \"../data/external/tp2_IPC_Indec.csv\"\n",
    "\n",
    "if exists(precios_path):\n",
    "    print('Este archivo ya existe.')\n",
    "else:\n",
    "    print('Este archivo no existe: ¡Vamos a crearlo!')\n",
    "    url = \"https://www.indec.gob.ar/ftp/cuadros/economia/sh_ipc_06_23.xls\"\n",
    "    df = pd.read_excel(url, sheet_name=\"Índices IPC Cobertura Nacional\", header=None, usecols=\"B:CA\", skiprows=[0, 1, 2, 3, 4, 6, 7, 8], nrows=2)\n",
    "    df = df.transpose()\n",
    "    df.columns = [\"Fecha\", \"INDICE\"]\n",
    "    df[\"Fecha\"] = pd.to_datetime(df[\"Fecha\"])\n",
    "    df.to_csv(precios_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir dataset de precios\n",
    "precios = pd.read_csv(precios_path)\n",
    "precios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay que asegurar que la variable clave tenga el mismo tipo en los dos dataframes\n",
    "precios[\"Fecha\"] = pd.to_datetime(precios[\"Fecha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_ipc = ventas_ipc.merge(precios[[\"Fecha\", \"INDICE\"]], on=\"Fecha\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexar(ventas_ipc, 'Ventas')\n",
    "indexar(ventas_ipc, 'Comision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se descartan las variables que no se usan\n",
    "ventas_ipc = limpiar_basic(ventas_ipc, cols_drop=['Ventas', 'Comision', 'INDICE'])\n",
    "\n",
    "# Se renombran las variables\n",
    "ventas_ipc.rename(columns = {'Ventas_Real': 'Ventas', \n",
    "                              'Comision_Real': 'Comision'}, inplace = True)\n",
    "\n",
    "# Se reacomodan las columnas\n",
    "ventas_ipc = ventas_ipc[['ID', 'Omega', 'Subrubro', 'Fecha', \n",
    "                          'Deposito', 'Ventas', 'Comision', 'Modelo']]\n",
    "\n",
    "ventas_ipc = ventas_ipc.sort_values(['Fecha', 'Ventas']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_fisc = ventas_ipc.copy()\n",
    "ventas_sub11 = ventas_fisc.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Para cada combinación posible de `Subrubro`, `ID` y `Fecha`, vamos a:\n",
    "* Sumar todos los valores de `Ventas`.\n",
    "* Sumar todos los valores de `Comision`.\n",
    "* Mantener los valores de `Modelo` y de `Omega`.\n",
    "\n",
    "Al hacer esto, se agregan en una única fila todas las observaciones que pertenezcan a un mismo vendedor en una dada fecha bajo un cierto subrubro, más allá del depósito desde el que se realiza la venta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregado = ventas_sub11.groupby(['Subrubro', 'ID', 'Fecha']).agg({\n",
    "    'Omega': 'min',\n",
    "    'Ventas': 'sum',\n",
    "    'Comision': 'sum',\n",
    "    'Modelo': 'min'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Existe la posibilidad de que algunos vendedores tengan siempre ventas nulas dentro de un mismo subrubro. Como no aportan información, nos deshacemos de estos registros. En efecto había 34650 registros que cumplían esta condición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregado_no_nulo = agregado.groupby(['Subrubro', 'ID']).filter(lambda x: (x['Ventas'] != 0).any()).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Deberíamos tener 42 observaciones por par ID/Subrubro, pero se ve al comienzo del dataframe anterior que falta, por ejemplo, el 5 del 2020 al vendedor 5 en \"Com Varios\". Esto pasa en varios casos: a veces hay meses faltantes. Vamos a imputar esos meses con valor 0 en ventas y comisión (esto es particularmente importante si luego vamos a hacer diferencias, por ej. para que no se encuentre con un vacío (genera diferencia vacía) o que me opere contra un mes que en realidad no es el anterior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedio_observaciones = agregado_no_nulo.groupby(['Subrubro', 'ID']).size().mean()\n",
    "\n",
    "# Mostrar el promedio de observaciones por combinación de ID y Subrubro\n",
    "print(promedio_observaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de proceder a rellenar los casos vacíos con valores cero, vamos a crear una variable que nos permita en el fututo distinguir los valores originales de los imputados (`Dato_original`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregado_no_nulo['Dato_original'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar las observaciones por combinación de ID y Subrubro\n",
    "conteo_combinaciones = agregado_no_nulo.groupby(['Subrubro', 'ID']).size().reset_index(name='Conteo')\n",
    "\n",
    "# Filtrar las combinaciones con menos de 42 observaciones\n",
    "combinaciones_faltantes = conteo_combinaciones[conteo_combinaciones['Conteo'] < 42]\n",
    "\n",
    "# Lista para almacenar las observaciones faltantes\n",
    "observaciones_faltantes = []\n",
    "\n",
    "# Iterar sobre las combinaciones faltantes\n",
    "for _, combinacion in combinaciones_faltantes.iterrows():\n",
    "    id_val = combinacion['ID']\n",
    "    subrubro_val = combinacion['Subrubro']\n",
    "    \n",
    "    # Obtener fechas existentes y fechas faltantes\n",
    "    fechas_existentes = agregado_no_nulo[(agregado_no_nulo['ID'] == id_val) & (agregado_no_nulo['Subrubro'] == subrubro_val)]['Fecha']\n",
    "    fechas_faltantes = set(agregado_no_nulo['Fecha'].unique()) - set(fechas_existentes)\n",
    "    \n",
    "    # Agregar observaciones faltantes al DataFrame\n",
    "    for fecha_faltante in fechas_faltantes:\n",
    "        observacion = {\n",
    "            'ID': id_val,\n",
    "            'Subrubro': subrubro_val,\n",
    "            'Fecha': fecha_faltante,\n",
    "            'Ventas': 0,\n",
    "            'Comision': 0,\n",
    "        }\n",
    "        observaciones_faltantes.append(observacion)\n",
    "\n",
    "# Crear DataFrame con las observaciones faltantes\n",
    "df_observaciones_faltantes = pd.DataFrame(observaciones_faltantes)\n",
    "\n",
    "# Agregar observaciones faltantes al DataFrame agregado_no_nulo\n",
    "agregado_limpio = pd.concat([agregado_no_nulo, df_observaciones_faltantes], ignore_index=True)\n",
    "\n",
    "# Mostrar el nuevo DataFrame con las observaciones faltantes agregadas\n",
    "agregado_limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputo los valores Omega y Modelo asociados a los nuevos meses adicionados. Es más eficiente agregarlo en una celda aparte y no en el for (antes demoraba 9 minutos, ahora menos de 1).\n",
    "agregado_limpio['Omega'] = agregado_limpio.groupby(['ID', 'Subrubro'])['Omega'].transform('max')\n",
    "agregado_limpio['Modelo'] = agregado_limpio.groupby(['ID', 'Subrubro'])['Modelo'].transform('max')\n",
    "\n",
    "# Relleno los valores nulos de Dato_original con 0.\n",
    "agregado_limpio['Dato_original'] = agregado_limpio['Dato_original'].fillna(0)\n",
    "\n",
    "agregado_limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las columnas 'Omega', 'Modelo' y 'Dato_original' a tipo int64\n",
    "agregado_limpio['Omega'] = agregado_limpio['Omega'].astype('int64')\n",
    "agregado_limpio['Modelo'] = agregado_limpio['Modelo'].astype('int64')\n",
    "agregado_limpio['Dato_original'] = agregado_limpio['Dato_original'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedio_observaciones = agregado_limpio.groupby(['Subrubro', 'ID']).size().mean()\n",
    "\n",
    "# Mostrar el promedio de observaciones por combinación de ID y Subrubro\n",
    "print(promedio_observaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Ordenar luego de todo lo que se hizo. Dejar que primero esté Fecha. Sirve para el pivoteo de la próxima sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registros_vendedores_abs = agregado_limpio.sort_values(['Fecha', 'Subrubro', 'ID']).reset_index(drop=True)\n",
    "registros_vendedores_abs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Queremos hacer el cálculo de la varación porcentual. Con el dataset como está actualmente (presencia de ceros), pueden generarse resultados que tienden a infinito. Para superar esta situación:\n",
    "* Los \"ceros al comienzo\" (el vendedor aún no formaba parte de la plataforma) se reemplazaron por NaN.\n",
    "* Los \"ceros en el medio\" (vendedor imputa venta nula) se reemplazaron por -1. Al principio íbamos a poner +1, pero existe un registro que tenía este valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registros_vendedores_rel = registros_vendedores_abs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demora poquito más de 2 min\n",
    "\n",
    "idx_borrar = np.array([])\n",
    "for rubro in registros_vendedores_rel['Subrubro'].unique():\n",
    "    print(rubro)\n",
    "    ids = registros_vendedores_rel[registros_vendedores_rel['Subrubro'] == rubro]['ID'].unique()\n",
    "\n",
    "    for id in ids:\n",
    "        a = registros_vendedores_rel[(registros_vendedores_rel['Subrubro'] == rubro) & (registros_vendedores_rel['ID'] == id)]\n",
    "        afec = a[a['Ventas'] > 0]['Fecha'].iloc[0]\n",
    "        aidx = a.index[a['Ventas'] > 0][0]\n",
    "        bidx = a.index[a['Ventas'] == 0]\n",
    "        cidx = bidx[bidx > aidx]\n",
    "        idx_borrar = np.concatenate([idx_borrar, cidx])\n",
    "\n",
    "idx_borrar = np.array(idx_borrar)\n",
    "idx_borrar = np.sort(idx_borrar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registros_vendedores_rel[['Ventas', 'Comision']] = registros_vendedores_rel[['Ventas', 'Comision']].replace({0:np.NaN})\n",
    "# La siguiente línea es para cambiar los ceros del medio por -1\n",
    "# registros_vendedores_rel.loc[idx_borrar, :] = registros_vendedores_rel.loc[idx_borrar, :].replace({np.NaN:-1})\n",
    "registros_vendedores_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Cálculo de cambios porcentuales. La función pct_change devuelve en el rango normal, no en el porcentual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_diferencia_porcentual(registros_vendedores_rel, 'Ventas', 12)\n",
    "crear_diferencia_porcentual(registros_vendedores_rel, 'Comision', 12)\n",
    "crear_diferencia_porcentual(registros_vendedores_rel, 'Ventas', 4)\n",
    "crear_diferencia_porcentual(registros_vendedores_rel, 'Comision', 4)\n",
    "registros_vendedores_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Pivotear los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivotear = registros_vendedores_rel.copy()\n",
    "\n",
    "# Extraer el mes y el año de la columna \"Fecha\"\n",
    "pivotear[\"Fecha\"] = pd.to_datetime(pivotear[\"Fecha\"])\n",
    "pivotear[\"Month\"] = pivotear[\"Fecha\"].dt.month\n",
    "pivotear[\"Year\"] = pivotear[\"Fecha\"].dt.year\n",
    "\n",
    "# Convertir \"Month\" a string con formato de dos cifras\n",
    "pivotear[\"Month\"] = pivotear[\"Month\"].apply(lambda x: str(x).zfill(2))\n",
    "\n",
    "# Convertir \"Year\" a string y quedarse con los últimos 2 dígitos\n",
    "pivotear[\"Year\"] = pivotear[\"Year\"].apply(lambda x: str(x)[-2:])\n",
    "\n",
    "# Crear la variable \"Fecha2\" que concatena \"Year\" y \"Month\"\n",
    "pivotear[\"Fecha2\"] = pivotear[\"Year\"] + pivotear[\"Month\"]\n",
    "\n",
    "# Eliminar columnas\n",
    "pivotear.drop(columns=['Fecha','Ventas','Comision','Dato_original','Month','Year'], inplace=True)\n",
    "\n",
    "# Renombrar la columnas\n",
    "pivotear.rename(columns={'Fecha2': 'Fecha', 'Y_pct_Ventas': 'Y_pct_Ven', 'Y_pct_Comision': 'Y_pct_Com', 'F_pct_Ventas': 'F_pct_Ven', 'F_pct_Comision': 'F_pct_Com'}, inplace=True)\n",
    "\n",
    "pivotear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar el pivoteo y la agrupación\n",
    "pivot_df = pivotear.pivot_table(index=[\"ID\",'Subrubro','Omega','Modelo'], columns=['Fecha'], values=['Y_pct_Ven', 'Y_pct_Com', 'F_pct_Ven', 'F_pct_Com'])\n",
    "\n",
    "# Generar los nombres de las columnas finales\n",
    "columns = [f\"{col[0]}_{col[1]}\" for col in pivot_df.columns]\n",
    "\n",
    "# Asignar los nuevos nombres de columnas\n",
    "pivot_df.columns = columns\n",
    "\n",
    "# Restablecer el índice para que \"ID\" vuelva a ser una columna\n",
    "pivot_df = pivot_df.reset_index()\n",
    "\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se hace el cálculo de promedio y varianza de los vectores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se sintetizan todos los pasos de curación, a fin de tener a mano en caso de tener que revisar alguno de ellos. (Por hacer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectores = pd.read_csv('../data/interim/tp2_vendedores_vector_resumen.csv')\n",
    "vectores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
